{"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":8.321236,"end_time":"2024-09-27T18:46:58.340288","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-09-27T18:46:50.019052","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"# Adapted from MYONN (Rashid 2016, 2024) by Hilary Abraham, 2024, for Science World BC\n# python notebook for Make Your Own Neural Network\n# code for a 3-layer neural network, and code for learning the MNIST dataset\n# (c) Tariq Rashid, 2016\n# license is GPLv2","metadata":{"execution":{"iopub.execute_input":"2024-09-27T18:46:52.928953Z","iopub.status.busy":"2024-09-27T18:46:52.928355Z","iopub.status.idle":"2024-09-27T18:46:52.934691Z","shell.execute_reply":"2024-09-27T18:46:52.933507Z"},"papermill":{"duration":0.015172,"end_time":"2024-09-27T18:46:52.937263","exception":false,"start_time":"2024-09-27T18:46:52.922091","status":"completed"},"tags":[]},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Add this to the neural network class definition\n    \n    \n    \n    # backquery the neural network\n    def backquery(self, targets_list):\n        # transpose the targets list to a vertical array\n        final_outputs = numpy.array(targets_list, ndmin=2).T\n        \n        # calculate the signal into the final output layer\n        final_inputs = self.inverse_activation_function(final_outputs)\n\n        # calculate the signal out of the hidden layer\n        hidden_outputs = numpy.dot(self.who.T, final_inputs)\n        # scale them back to 0.01 to .99\n        hidden_outputs -= numpy.min(hidden_outputs)\n        hidden_outputs /= numpy.max(hidden_outputs)\n        hidden_outputs *= 0.98\n        hidden_outputs += 0.01\n        \n        # calculate the signal into the hidden layer\n        hidden_inputs = self.inverse_activation_function(hidden_outputs)\n        \n        # calculate the signal out of the input layer\n        inputs = numpy.dot(self.wih.T, hidden_inputs)\n        # scale them back to 0.01 to .99\n        inputs -= numpy.min(inputs)\n        inputs /= numpy.max(inputs)\n        inputs *= 0.98\n        inputs += 0.01\n        \n        return inputs","metadata":{"_kg_hide-input":false,"execution":{"iopub.execute_input":"2024-09-27T18:46:53.405736Z","iopub.status.busy":"2024-09-27T18:46:53.405191Z","iopub.status.idle":"2024-09-27T18:46:53.424347Z","shell.execute_reply":"2024-09-27T18:46:53.423087Z"},"papermill":{"duration":0.02797,"end_time":"2024-09-27T18:46:53.427152","exception":false,"start_time":"2024-09-27T18:46:53.399182","status":"completed"},"tags":[]},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Add this cell anytime after training the neural network\n# change the label variable to change the queried number\n\n\n\n# backwards query\n\n# run the network backwards, given a label, see what image it produces\n\n# label to test\nlabel = 0\n# create the output signals for this label\ntargets = numpy.zeros(output_nodes) + 0.01\n# all_values[0] is the target label for this record\ntargets[label] = 0.99\nprint(targets)\n\n# get image data\nimage_data = n.backquery(targets)\n\n# plot image data\nmatplotlib.pyplot.imshow(image_data.reshape(28,28), cmap='Greys', interpolation='None')","metadata":{"papermill":{"duration":0.268359,"end_time":"2024-09-27T18:46:57.914263","exception":false,"start_time":"2024-09-27T18:46:57.645904","status":"completed"},"tags":[],"_kg_hide-output":false},"execution_count":null,"outputs":[]}]}